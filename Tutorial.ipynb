{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SolAster Tutorial\n",
    "## Sun-as-a-Star Workshop, Flatiron, 13-17/03/2023\n",
    "How to generate Sun-as-a-Star varaibles from SDO/HMI images\n",
    "\n",
    "Pipeline described in [Haywood et al. 2016](https://ui.adsabs.harvard.edu/abs/2016csss.confE..47H/abstract) and [Ervin et al. 2022](https://ui.adsabs.harvard.edu/abs/2022AJ....163..272E/abstractr)\n",
    "\n",
    "Github: [SolAster Github](https://github.com/tamarervin/SolAster)\n",
    "Website: [SolAster Website](https://tamarervin.github.io/SolAster/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install SolAster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "import SolAster.tools.rvs as rvs\n",
    "import SolAster.tools.calculation_funcs as sfuncs\n",
    "import SolAster.tools.lbc_funcs as lbfuncs\n",
    "import SolAster.tools.coord_funcs as ctfuncs\n",
    "import SolAster.tools.utilities as utils\n",
    "from SolAster.tools.settings import *\n",
    "from SolAster.tools.plotting_funcs import hmi_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading images with Sunpy\n",
    "\n",
    "Sunpy is a python package to access and make use of solar data.\n",
    "\n",
    "We will use it to download SDO images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each timestamp, we need to download a continuum intensity map, a Dopplergram, and a line-of-sight magnetogram, using the `search` function in `Fido`.\n",
    "\n",
    "Example use:\n",
    "```\n",
    "matching_images = Fido.search(\n",
    "    a.Time('2014-01-01T00:00:00', '2014-01-01T00:12:00'),\n",
    "    a.jsoc.Series('hmi.Ic_720s'),\n",
    "    a.jsoc.Notify('example@email.com')\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "`a.Time` specifies the time range in which we want to search for data. \n",
    "\n",
    "`a.jsoc.Series` tells jsoc which data products we want to access. In this case, we are getting the 720 second exposure (`720s`),  continuum intensitygrams (`Ic`) obtained from the Helioseismic and Magnetic Imager (`hmi`). The table below shows the relevant parameters to pass to `Series` for the data products we will be using.\n",
    "\n",
    "|Data type | jsoc Series |\n",
    "| ---- | --- |\n",
    "| Intensitygram | `hmi.Ic_720s`| \n",
    "| Magnetogram | `hmi.m_720s`| \n",
    "| Dopplergram | `hmi.v_720s`| \n",
    "\n",
    "\n",
    "\n",
    "`a.jsoc.Notify` tells jsoc which user is accessing the data, you will get a confirmation email each time you download the data.\n",
    "\n",
    "Another useful parameter to pass to `search` includes, e.g., `a.Sample(12*u.hour)` if we wanted to only get data every 12 hours for the duration of the specified time range.\n",
    "\n",
    "Once we have identified all the matching available data products using `Fido.search`, we call\n",
    "\n",
    "```\n",
    "downloaded_files = Fido.fetch(matching_images, path='./path/{file}')\n",
    "```\n",
    "to download the relevant images, and save them in `./path/`. \n",
    "\n",
    "The `downloaded_files` object is a list of filepaths of the images.\n",
    "\n",
    "Make sure to change `your@email.com` to the email that you abilitated for the download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"your@email.com\"\n",
    "\n",
    "continuum_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.Ic_720s'), a.jsoc.Notify(email))\n",
    "continuum_download = Fido.fetch(continuum_search, path='./sunpy_downloads/{file}')\n",
    "\n",
    "magnetogram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.m_720s'), a.jsoc.Notify(email))\n",
    "magnetogram_download = Fido.fetch(magnetogram_search, path='./sunpy_downloads/{file}')\n",
    "\n",
    "dopplergram_search = Fido.search(a.Time('2014-01-01T00:00:00', '2014-01-01T00:05:00'), a.jsoc.Series('hmi.V_720s'), a.jsoc.Notify(email))\n",
    "dopplergram_download = Fido.fetch(dopplergram_search, path='./sunpy_downloads/{file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above snippet, we are searching for files with timestamps between 2014-01-01T00:00:00 and 2014-01-01T00::00 (i.e., just short of the 720s cadence of the images). \n",
    "\n",
    "This ensures that we only fetch a single set of images, in practice we could have equally chosen 2014-01-01T00:00:00 and 2014-01-01T00:00:01 as the time range to search, whereas setting the upper limit as 2014-01-01T00:12:00 would fetch two sets of images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case no email was setup beforehand, the download is taking too long or `sunpy` is misbehaving as a whole, you can use the pre-downloaded imaged in the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of emergency break glass\n",
    "bad_sunpy = False\n",
    "\n",
    "if bad_sunpy:\n",
    "    print('Using backup data')\n",
    "    all_files = os.listdir('./sunpy_downloads_backup/')\n",
    "    magnetogram_download = ['./sunpy_downloads_backup/' + i for i in all_files if 'magnetogram' in i]\n",
    "    continuum_download = ['./sunpy_downloads_backup/'+i for i in all_files if 'continuum' in i]\n",
    "    dopplergram_download = ['./sunpy_downloads_backup/' + i for i in all_files if 'Dopplergram' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_download = magnetogram_download + continuum_download + dopplergram_download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving File Setup\n",
    "Here we generate the csv file in which we will be saving our data.\n",
    "\n",
    "We will use `panda DataFrames`. This is not a requirement and the preferred method of storing data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of csv file to store calculations\n",
    "csv_name = 'timeseries'\n",
    "\n",
    "# create file names\n",
    "current_position = Path().resolve()\n",
    "csv_file = os.path.join(current_position,csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(current_position,csv_name+'_bad_dates.csv')\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f', 'Bobs',\n",
    "                'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage', 'f_nonconv',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'unsigned_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "df = pd.DataFrame({i: [] for i in row_contents})\n",
    "df.to_csv(f'./{csv_name}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at the downloaded images\n",
    "\n",
    "We will now read the downloaded images. We will create three 2d arrays from the fits files:\n",
    "\n",
    "`imap`: Intensity map\n",
    "\n",
    "`vmap`: Doppler map\n",
    "\n",
    "`mmap`: Magnetic map\n",
    "\n",
    "\n",
    "These can be plotted with `pyplot.imshow()`. Here we just have a quick `.peek()` at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unusable file types\n",
    "good_files = []\n",
    "for file in file_download:\n",
    "    name, extension = os.path.splitext(file)\n",
    "    if extension == '.fits':\n",
    "        good_files.append(file)\n",
    "\n",
    "# convert to map sequence\n",
    "map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "# check for missing data types\n",
    "missing_map = False\n",
    "# split into data types\n",
    "for j, map_obj in enumerate(map_seq):\n",
    "    if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "        vmap = map_obj\n",
    "    elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "        mmap = map_obj\n",
    "    elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "        imap = map_obj\n",
    "\n",
    "# coordinate transformation for maps\n",
    "x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "# remove bad mu values\n",
    "vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap])\n",
    "\n",
    "# quick peeks at the uncorrected images\n",
    "vmap.peek()\n",
    "mmap.peek()\n",
    "imap.peek()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Corrections\n",
    "\n",
    "The downloaded images will require some correction before use.\n",
    "\n",
    "### Velocity Corrections\n",
    "\n",
    "To compute the actual surface velocity, we need to subtract from the Dopplergram the spacecraft velocity `vsc` and the solar rotational velocity `vrot`.\n",
    "\n",
    "We save the new corrected Dopplergram as `map_vel_corr` and take a peek at it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Velocity Corrections ######\n",
    "# calculate relative positions\n",
    "deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "# calculate spacecraft velocity\n",
    "vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "# optimized solar rotation parameters\n",
    "a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "# calculation of solar rotation velocity\n",
    "vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "# calculate corrected velocity\n",
    "corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "# corrected velocity maps\n",
    "map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "map_vel_cor.peek()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limb Darkening\n",
    "\n",
    "We flatten the intensitygram by dividing it by a limbdarkening polynomial.\n",
    "\n",
    "The u and v coefficients are taken from **Allen 1973** based on the wavelength value. `SolAster` computed the polynomia in the `limb_polynomial` function. Its output is an array of the same size as the maps.\n",
    "\n",
    "We save the flattened intensity map as `map_int_cor` and take a peek at it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Limb Darkening Corrections ######\n",
    "# limb brightening\n",
    "Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "# calculate corrected data\n",
    "Iflat = imap.data / Lij\n",
    "\n",
    "# corrected intensity maps\n",
    "map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "map_int_cor.peek()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnetic Foreshortening\n",
    "\n",
    "We also include a correction for magnetic foreshortening. To do so we need to compute the unsigned magnetic field strength and magnetic noise. `SolAster` does so with the `mag_field` function.\n",
    "\n",
    "Using the `Br` output we can generate a map of the true radial magnetic field, saved as `map_mag_cor`. We take a peek at it here.\n",
    "\n",
    "We also include a bit of code to re-normalize and plot the magnetic field, for easier viewing.\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Magnetogram #####\n",
    "\n",
    "# calculate unsigned field strength to correct for foreshortening \n",
    "Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "# corrected observed magnetic data map\n",
    "map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "# true radial magnetic data map\n",
    "map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "#map_mag_obs.peek()\n",
    "map_mag_cor.peek()\n",
    "\n",
    "# to see a bit better\n",
    "normalize=False\n",
    "if normalize:\n",
    "    map_mag_cor.plot_settings['norm'] = plt.Normalize(-100, 100)\n",
    "    map_mag_cor.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding threshold values\n",
    "\n",
    "We identify magnetic regions based on a magnetic cut-off value of 24 Gauss, taken from Yeo et. al. 2013. \n",
    "\n",
    "We can now divide the Sun into _active_ and _inactive_ regions.\n",
    "\n",
    "Within these regions we can separate between bright active regions (which we can later further divide into network and plage/faculae) and dark active regions (spots). We map both into `fac_map` and `spot_map` and have a peek at them.\n",
    "\n",
    "We finally generate a single map that identifies both, `map_full_thresh`. We include a commented-out line at the end to plot our new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Find thresholds #####\n",
    "# calculate magnetic threshold\n",
    "#active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "active,quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "map_mag_thresh = sfuncs.corrected_map(active, mmap, map_type='Magnetic-Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "#map_mag_thresh.peek()\n",
    "\n",
    "\n",
    "\n",
    "# calculate intensity threshold\n",
    "fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "# create faculae map objects\n",
    "fac_map = sfuncs.corrected_map(fac_inds, mmap, map_type='Faculae', frame=frames.HeliographicCarrington)\n",
    "\n",
    "# create sunspot map objects\n",
    "spot_map = sfuncs.corrected_map(spot_inds, mmap, map_type='Sunspot', frame=frames.HeliographicCarrington)\n",
    "\n",
    "fac_map.peek()\n",
    "spot_map.peek()\n",
    "\n",
    "\n",
    "# create threshold array\n",
    "thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "# full threshold maps\n",
    "map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "\n",
    "\n",
    "\n",
    "#hmi_plot(map_int_cor, map_mag_obs, map_vel_cor, fac_inds, spot_inds, mu, save_fig=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Factors\n",
    "\n",
    "From the identification of the active and inactive areas on the Sun we can now calculate the filling factors of bright regions and spots as a percentage of the total visible surface. To do so, `SolAster` uses the function `filling_factor`.\n",
    "\n",
    "To include the size dependence of the active regions, `SolAster` uses the function `area_filling_factor`. We can now derive the filling factors of plage and network separately (their sum will be equal to the bright region filling factor called `f_fac`). We can also derve the fraction of small to large active regions. This separation is introduced in Milbourne et al. 2019 and will be relevant when computing the radial velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute filling factors\n",
    "f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "print(f'Bright regions: {f_bright:.2f}%')\n",
    "print(f'Spots: {f_spot:.2f}%')\n",
    "\n",
    "### calculate the area filling factor\n",
    "pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "area = sfuncs.area_calc(active, pixA_hem)\n",
    "f_small, f_large, f_network, f_plage = sfuncs.area_filling_factor(active, area, mu, mmap,\n",
    "                                                                             fac_inds, athresh=Parameters.athresh,\n",
    "                                                                             mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "print(f'Plage or faculae regions: {f_plage:.2f}%')\n",
    "print(f'Bright Network: {f_network:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Velocity Derivation\n",
    "\n",
    "We here follow the radial velocity derivation explained in Haywood et al. 2016 and Milbourne et al. 2019.\n",
    "\n",
    "Radial velocities in SDO/HMI images are usually considered $\\Delta$ RVs, since they depend on the Quiet-sun velocity (the average velocity of the non-magnetically active areas of the Sun).\n",
    "\n",
    "The $\\Delta$ RVs are computed from a model, a linear combination of two components: `v_phot` and `v_conv`.\n",
    "\n",
    "`v_phot` is the velocity contribution due to the rotational Doppler imbalance generated by active regions. `v_conv` is the velocity contribution due to suppression of convective blueshift by active regions.\n",
    "\n",
    "`rv_model` = `A`x`v_phot`+`B`x`v_conv`+`RV0`\n",
    "\n",
    "The coefficients `A` and `B` depend on the telescope after which the SDO velocities are being normalized, and `RV0` is the required offset. We here explicitely list these values and in this tutorial we exclude the offset in the calculation to get the \"raw\" RV model. `SolAster` can directly compute the rv_model including offset with `calc_model`, depending on the selected instrument.\n",
    "\n",
    "At the moment only HARPS-N and NEID normalisation is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Radial Velocity Computations in m/s #####\n",
    "\n",
    "### velocity contribution due to convective motion of quiet-Sun\n",
    "v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "# calculate photospheric velocity\n",
    "v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "# calculate disc-averaged velocity\n",
    "v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "# calculate convective velocity\n",
    "v_conv = v_disc - v_quiet\n",
    "\n",
    "print(f'Photmetric velocity: {v_phot:.2f} m/s')\n",
    "print(f'Convective velocity: {v_conv:.2f} m/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = \"HARPS-N\"\n",
    "#inst = \"NEID\"\n",
    "\n",
    "if inst.startswith(\"H\"):\n",
    "    # HARPS-N values\n",
    "    A = 2.101\n",
    "    B = 0.9825\n",
    "    RV0 = 97.08\n",
    "elif inst.startswith(\"N\"):\n",
    "    # NEID values\n",
    "    A = 1.0983\n",
    "    B = 1.423\n",
    "    RV0 = -646.076\n",
    "    print(2)\n",
    "else:\n",
    "    raise \"Unknown instrument\"\n",
    "\n",
    "#rv_model = rvs.calc_model(\"HARPS-N\", v_conv, v_phot)\n",
    "rv_model = A * v_phot + B * v_conv\n",
    "\n",
    "print(f'Derived radial velocity: {rv_model:.2f} m/s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetic Fluxes\n",
    "\n",
    "Studies such as Haywood et al. 2022 and Rescigno et al. (in prep) make use of the Sun-as-a-Star magnetic flux measurements derived from SDO/HMi images. We include how to compute them in the following section using the `SolAster` function `area_unsigned_flux`.\n",
    "\n",
    "Here the unsigned (absolute) magnetic flux is saved as `unsigned_obs_flux`, while the polarised (longitudinal) magnetic flux is `pol_flux`. Both are in Gauss.\n",
    "\n",
    "Other interesting values are: `quiet_flux` is the magnetic flux of the magnetically quiet regions, `ar_flux` the one of the magnetically active ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Magnetic Flux\n",
    "\n",
    "unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                        area,\n",
    "                                                                                        active,\n",
    "                                                                                    athresh=Parameters.athresh)\n",
    "\n",
    "### get area weighted convective velocities\n",
    "vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "\n",
    "print(f'Unsigned Magnetic Flux: {unsigned_obs_flux:.2f} G')\n",
    "print(f'Signed Magnetic Flux: {pol_flux:.2f} G')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data\n",
    "\n",
    "Now that we derived the main outputs of `SolAster`, we can save them. We again use `panda.DataFrame` to save to a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of what we want to save\n",
    "\n",
    "save_vals = {\n",
    "    \"rv_model\":rv_model,\n",
    "     \"v_quiet\":v_quiet,\n",
    "     \"v_disc\":v_disc,\n",
    "     \"v_phot\":v_phot,\n",
    "     \"v_conv\":v_conv,\n",
    "     \"f_bright\":f_bright,\n",
    "     \"f_spot\":f_spot,\n",
    "     \"f\":f,\n",
    "     \"unsigned_obs_flux\":unsigned_obs_flux,\n",
    "     \"vphot_bright\":vphot_bright,\n",
    "     \"vphot_spot\":vphot_spot,\n",
    "     \"f_small\":f_small,\n",
    "     \"f_large\":f_large,\n",
    "     \"f_network\":f_network,\n",
    "     \"f_plage\":f_plage,\n",
    "     \"quiet_flux\":quiet_flux,\n",
    "     \"ar_flux\":ar_flux,\n",
    "     \"conv_flux\":conv_flux,\n",
    "     \"pol_flux\":pol_flux,\n",
    "     \"unsigned_flux\":unsigned_obs_flux,\n",
    "     \"pol_conv_flux\":pol_conv_flux,\n",
    "     \"vconv_quiet\":vconv_quiet,\n",
    "     \"vconv_large\":vconv_large,\n",
    "     \"vconv_small\":vconv_small\n",
    "}\n",
    "\n",
    "\n",
    "# save these values to the csv file\n",
    "df = pd.concat((df,pd.DataFrame(save_vals, index=[0])))\n",
    "df.to_csv(f'./{csv_name}.csv')\n",
    "# print that the date is completed\n",
    "print('\\nCalculations and save to file complete')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating with multiple images\n",
    "\n",
    "Here we present the same process re-organized to be iterable, from data download to saving to file.\n",
    "\n",
    "We also present another way of featching data with Fido.\n",
    "\n",
    "This full tutorial and similar ones can be found at the [SolAster Website](https://tamarervin.github.io/SolAster/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date range\n",
    "start_date = datetime.datetime(2014, 8, 10, 0, 00, 0)\n",
    "end_date = datetime.datetime(2014, 8, 16, 0, 00, 0)\n",
    "\n",
    "# query cadence in seconds (to download a single image per day, pick cadence = to a day)\n",
    "cadence = 24*3600\n",
    "\n",
    "# name of instrument to use for calculation of RV model\n",
    "# choose either 'NEID' or 'HARPS-N'\n",
    "inst = 'HARPS-N'\n",
    "\n",
    "# get hmi data products\n",
    "time_range = datetime.timedelta(seconds=22)\n",
    "physobs_list = [a.Physobs.los_velocity, a.Physobs.los_magnetic_field, a.Physobs.intensity]\n",
    "\n",
    "# get dates list\n",
    "xy = (end_date - start_date).seconds + (end_date - start_date).days * 24 * 3600\n",
    "dates_list = [start_date + datetime.timedelta(seconds=cadence*x) for x in range(0, int(xy/cadence))]\n",
    "\n",
    "\n",
    "# name of csv file to store calculations\n",
    "csv_name = 'timeseries_iterated'\n",
    "\n",
    "# create file names\n",
    "current_position = Path().resolve()\n",
    "csv_file = os.path.join(current_position,+csv_name+'.csv')\n",
    "bad_dates_csv = os.path.join(current_position,+csv_name+'_bad_dates.csv')\n",
    "\n",
    "# List of header strings\n",
    "row_contents = ['date_obs', 'date_jd', 'v_quiet', 'v_disc', 'v_phot', 'v_conv', 'f_bright', 'f_spot', 'f', 'Bobs',\n",
    "                'vphot_bright', 'vphot_spot', 'f_small', 'f_large', 'f_network', 'f_plage', 'f_nonconv',\n",
    "                'quiet_flux', 'ar_flux', 'conv_flux', 'unsigned_flux', 'pol_flux', 'pol_conv_flux', 'vconv_quiet', 'vconv_large',\n",
    "                'vconv_small']\n",
    "\n",
    "df = pd.DataFrame({i: [] for i in row_contents})\n",
    "df.to_csv(f'./{csv_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates_list):\n",
    "    # convert the date to a string -- required for use in csv file\n",
    "    date_str, date_obj, date_jd = utils.get_dates(date)\n",
    "\n",
    "    # pull image within specified time range\n",
    "    result = Fido.search(a.Time(str(date_obj - time_range), str(date_obj + time_range)),\n",
    "                        a.Instrument.hmi, physobs_list[0] | physobs_list[1] | physobs_list[2])\n",
    "\n",
    "    # add file to list\n",
    "    fido_download_path = os.path.join(current_position,\"sunpy_download/{file}\")\n",
    "    file_download = Fido.fetch(result, path=fido_download_path)\n",
    "    \n",
    "    # remove unusable file types\n",
    "    good_files = []\n",
    "    for file in file_download:\n",
    "        name, extension = os.path.splitext(file)\n",
    "        if extension == '.fits':\n",
    "            good_files.append(file)\n",
    "\n",
    "    if len(good_files) != 3:\n",
    "        # add the data\n",
    "        # append these values to the csv file\n",
    "        save_vals = [date_str, 'not three good files']\n",
    "        # print that the files are missing\n",
    "        print('\\nNot three good files: ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "        pass\n",
    "    else:\n",
    "        # convert to map sequence\n",
    "        map_seq = sunpy.map.Map(sorted(good_files))\n",
    "\n",
    "        # check for missing data types\n",
    "        missing_map = False\n",
    "        # split into data types\n",
    "        for j, map_obj in enumerate(map_seq):\n",
    "            if map_obj.meta['content'] == 'DOPPLERGRAM':\n",
    "                vmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'MAGNETOGRAM':\n",
    "                mmap = map_obj\n",
    "            elif map_obj.meta['content'] == 'CONTINUUM INTENSITY':\n",
    "                imap = map_obj\n",
    "            else:\n",
    "                missing_map = True\n",
    "\n",
    "        if missing_map:\n",
    "            print(\"Missing a data product for \" + date_str)\n",
    "\n",
    "            # add the data\n",
    "            # append these values to the csv file\n",
    "            save_vals = [date_str, 'missing data product']\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # coordinate transformation for maps\n",
    "            x, y, pdim, r, d, mu = ctfuncs.coordinates(vmap)\n",
    "            wij, nij, rij = ctfuncs.vel_coords(x, y, pdim, r, vmap)\n",
    "\n",
    "            # remove bad mu values\n",
    "            vmap, mmap, imap = ctfuncs.fix_mu(mu, [vmap, mmap, imap])\n",
    "\n",
    "            # calculate relative positions\n",
    "            deltaw, deltan, deltar, dij = sfuncs.rel_positions(wij, nij, rij, vmap)\n",
    "\n",
    "            # calculate spacecraft velocity\n",
    "            vsc = sfuncs.spacecraft_vel(deltaw, deltan, deltar, dij, vmap)\n",
    "\n",
    "            # optimized solar rotation parameters\n",
    "            a_parameters = [Parameters.a1, Parameters.a2, Parameters.a3]\n",
    "\n",
    "            # calculation of solar rotation velocity\n",
    "            vrot = sfuncs.solar_rot_vel(wij, nij, rij, deltaw, deltan, deltar, dij, vmap, a_parameters)\n",
    "\n",
    "            # calculate corrected velocity\n",
    "            corrected_vel = vmap.data - np.real(vsc) - np.real(vrot)\n",
    "\n",
    "            # corrected velocity maps\n",
    "            map_vel_cor = sfuncs.corrected_map(corrected_vel, vmap, map_type='Corrected-Dopplergram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # limb brightening\n",
    "            Lij = lbfuncs.limb_polynomial(imap)\n",
    "\n",
    "            # calculate corrected data\n",
    "            Iflat = imap.data / Lij\n",
    "\n",
    "            # corrected intensity maps\n",
    "            map_int_cor = sfuncs.corrected_map(Iflat, imap, map_type='Corrected-Intensitygram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate unsigned field strength\n",
    "            Bobs, Br = sfuncs.mag_field(mu, mmap, B_noise=Parameters.B_noise, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # corrected observed magnetic data map\n",
    "            map_mag_obs = sfuncs.corrected_map(Bobs, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # radial magnetic data map\n",
    "            map_mag_cor = sfuncs.corrected_map(Br, mmap, map_type='Corrected-Magnetogram',\n",
    "                                               frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # calculate magnetic threshold\n",
    "            active, quiet = sfuncs.mag_thresh(mu, mmap, Br_cutoff=Parameters.Br_cutoff, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            # calculate intensity threshold\n",
    "            fac_inds, spot_inds = sfuncs.int_thresh(map_int_cor, active, quiet)\n",
    "\n",
    "            # create threshold array\n",
    "            thresh_arr = sfuncs.thresh_map(fac_inds, spot_inds)\n",
    "\n",
    "            # full threshold maps\n",
    "            map_full_thresh = sfuncs.corrected_map(thresh_arr, mmap, map_type='Threshold',\n",
    "                                                   frame=frames.HeliographicCarrington)\n",
    "\n",
    "            # create diagnostic plots\n",
    "            if i == 0:\n",
    "                if diagnostic_plots:\n",
    "                    hmi_plot(map_int_cor, map_mag_obs, map_vel_cor, fac_inds, spot_inds, mu, save_fig=save_fig)\n",
    "\n",
    "            ### velocity contribution due to convective motion of quiet-Sun\n",
    "            v_quiet = sfuncs.v_quiet(map_vel_cor, imap, quiet)\n",
    "\n",
    "            ### velocity contribution due to rotational Doppler imbalance of active regions (faculae/sunspots)\n",
    "            # calculate photospheric velocity\n",
    "            v_phot, vphot_bright, vphot_spot = sfuncs.v_phot(quiet, active, Lij, vrot, imap, mu, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### velocity contribution due to suppression of convective blueshift by active regions\n",
    "            # calculate disc-averaged velocity\n",
    "            v_disc = sfuncs.v_disc(map_vel_cor, imap)\n",
    "\n",
    "            # calculate convective velocity\n",
    "            v_conv = v_disc - v_quiet\n",
    "\n",
    "            ### filling factor\n",
    "            # calculate filling factor\n",
    "            f_bright, f_spot, f = sfuncs.filling_factor(mu, mmap, active, fac_inds, spot_inds, mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### unsigned magnetic flux\n",
    "            # unsigned observed flux\n",
    "            unsigned_obs_flux = sfuncs.unsigned_flux(map_mag_obs, imap)\n",
    "\n",
    "            ### calculate the area filling factor\n",
    "            pixA_hem = ctfuncs.pix_area_hem(wij, nij, rij, vmap)\n",
    "            area = sfuncs.area_calc(active, pixA_hem)\n",
    "            f_small, f_large, f_network, f_plage = sfuncs.area_filling_factor(active, area, mu, mmap,\n",
    "                                                                                         fac_inds, athresh=Parameters.athresh,\n",
    "                                                                                         mu_cutoff=Parameters.mu_cutoff)\n",
    "\n",
    "            ### get the unsigned flux\n",
    "            quiet_flux, ar_flux, conv_flux, pol_flux, pol_conv_flux = sfuncs.area_unsigned_flux(map_mag_obs, imap,\n",
    "                                                                                                    area,\n",
    "                                                                                                    active,\n",
    "                                                                                                athresh=Parameters.athresh)\n",
    "\n",
    "            ### get area weighted convective velocities\n",
    "            vconv_quiet, vconv_large, vconv_small = sfuncs.area_vconv(map_vel_cor, imap, active, area, athresh=Parameters.athresh)\n",
    "\n",
    "            ### calculate model RV\n",
    "            rv_model = rvs.calc_model(inst, v_conv, v_phot)\n",
    "            \n",
    "            save_vals = {\n",
    "                \"rv_model\":rv_model,\n",
    "                 \"v_quiet\":v_quiet,\n",
    "                 \"v_disc\":v_disc,\n",
    "                 \"v_phot\":v_phot,\n",
    "                 \"v_conv\":v_conv,\n",
    "                 \"f_bright\":f_bright,\n",
    "                 \"f_spot\":f_spot,\n",
    "                 \"f\":f,\n",
    "                 \"unsigned_obs_flux\":unsigned_obs_flux,\n",
    "                 \"vphot_bright\":vphot_bright,\n",
    "                 \"vphot_spot\":vphot_spot,\n",
    "                 \"f_small\":f_small,\n",
    "                 \"f_large\":f_large,\n",
    "                 \"f_network\":f_network,\n",
    "                 \"f_plage\":f_plage,\n",
    "                 \"quiet_flux\":quiet_flux,\n",
    "                 \"ar_flux\":ar_flux,\n",
    "                 \"conv_flux\":conv_flux,\n",
    "                 \"pol_flux\":pol_flux,\n",
    "                 \"unsigned_flux\":unsigned_obs_flux,\n",
    "                 \"pol_conv_flux\":pol_conv_flux,\n",
    "                 \"vconv_quiet\":vconv_quiet,\n",
    "                 \"vconv_large\":vconv_large,\n",
    "                 \"vconv_small\":vconv_small\n",
    "                }\n",
    "\n",
    "\n",
    "            # save these values to the csv file\n",
    "            ######### check for index!!!!\n",
    "            df = pd.concat((df,pd.DataFrame(save_vals, index=[0])))\n",
    "            df.to_csv(f'./{csv_name}.csv')\n",
    "\n",
    "            # print that the date is completed\n",
    "            print('\\nCalculations and save to file complete for ' + date_str + ' index: ' + str(i))\n",
    "\n",
    "print('Calculation complete for dates:', start_date, 'to', end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff616b1659fc3860cc024fa76dfe1a60f886fc6e629cbf7b5197c3744c118f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
